{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_noy5Qc4e4P"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install torch  #YOLOv5 runs on top of PyTorch, so we need to import it to the notebook\n",
        "\n",
        "import torch # YOLOv5 implemented using pytorch\n",
        "from IPython.display import Image #this is to render predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!pip install -r /content/yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QA2fLSAwFQdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function of model\n",
        "def bounding_box_finder(<img_path>, <level_of_confidence = 0.5>):\n",
        "  \"\"\"\n",
        "  Enter a path and a number \n",
        "  : param img_path : First input to bounding_box_finder\n",
        "  : type img_path : str or list \n",
        "  : param level_of_confidence : Second input to bounding_box_finder\n",
        "  : type level_of_confidence : float \n",
        "  : results : bounding box\n",
        "  : rtype : list or pandas\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  count = 0 \n",
        "\n",
        "  if type(img_path) == str:\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/data/weightE100/best.pt')\n",
        "    results = model(img_path)\n",
        "    if len(results.pandas().xyxy[0].index)==0:\n",
        "      print(f\"I am unable to draw bounding box for: {img_path}\")\n",
        "    else:   \n",
        "      if results.pandas().xyxy[0].confidence[0] >= level_of_confidence:\n",
        "        print(f\"{results.pandas().xyxy} is result for {img_path}\")  # img predictions (pandas)\n",
        "      else:\n",
        "        print(f\"The confidence of bounding box is : {img_path}  with choosen confidence\")  \n",
        "\n",
        "  elif type(img_path) == list:\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/data/weightE100/best.pt')\n",
        "    results = model(img_path)\n",
        "\n",
        "    for i in range(len(img_path)):\n",
        "      if len(results.pandas().xyxy[i].index)==0:\n",
        "        print(f\"I am unable to draw bounding box for: {img_path[i]}\")\n",
        "        print(\"-----------------------\")\n",
        "        i+=1\n",
        "      else:\n",
        "        if results.pandas().xyxy[i].confidence[0] >= level_of_confidence:\n",
        "          count+=1  \n",
        "          print(f\"{results.pandas().xyxy[i]}\")\n",
        "          print(f\"is result for {img_path[i]}\")\n",
        "          print(f\"Model predict {count}  images from {len(img_path)}\") \n",
        "          print(\"----------------------\") \n",
        "          i+=1\n",
        "        \n",
        "          \n",
        "        else:\n",
        "          print(f\"I am unable to draw bounding box for: {img_path[i]}  with choosen confidence\")\n",
        "          print(\"----------------------\") \n",
        "  else:\n",
        "     print(\"Please Input a path of image file\")   \n"
      ],
      "metadata": {
        "id": "KyUFzMB1FQLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"-----\"\n",
        "level_of_confidence = ----\n",
        "bounding_box_finder(<img_path>, <level_of_confidence >)"
      ],
      "metadata": {
        "id": "j_0BAxu5MYVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}